---
layout: post
title: 基于GMM-HMM的语音识别笔记（一）
date: 2021-05-21 19:22:21 +0800
categories: 语音识别
tag: 
- HMM
- GMM
---

* content
{:toc}
[数字语音处理 李琳山老师](http://speech.ee.ntu.edu.tw/DSP2019Spring/) 学习笔记

### 隐马尔可夫模型（HMM）

从一个简单的状态模型分析，如果我们有这样的两个模型：「模型A」和「模型B」

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210525232943.png!small" alt="image-20210525232928046" style="zoom:50%;" />

+ 模型A表示：state1有0.9的可能性切换到state2，有0.1的可能性维持在state1
+ 模型B表示：state1有0.1的可能性切换到state2，有0.9的可能性维持在state1

因此`隐马尔可夫模型HMM`就类似于我们判断的一种思维方式

🌰例如，我们看到一串通过两个模型中的一个生成的状态序列X，状态如下：

S1->S1->S1->S1->S1->S1->S2->…

我们就很理所当然的认为这一串序列是由模型B产生出来的，因为模型B在state1时有很大的概率会维持在自身，而模型A在state1时很容易就转换到了下一个状态，而这种主观意识上的判断，计算机可以通过HMM模型实现

因此当我们放在state更多的语音信号模型中时，我们将语音信号解析成为对应的状态，通过状态间的切换关系，HMM就可以判断出其最有可能符合哪一个模型，从而判断出这句语音信号的意思

### 高斯混合模型（GMM）

图文部分引用来源 [一文详解高斯混合模型原理](https://zhuanlan.zhihu.com/p/31103654)

*高斯混合模型是对高斯模型进行简单的扩展，GMM使用多个高斯分布的组合来刻画数据分布。*

#### 高斯模型

如果我们对大量的人口进行身高数据的随机采样，绘制的到如下的柱状模型

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526081526.jpeg!small" alt="img" style="zoom:50%;" />

该模型的主要峰值集中在175\~180附近，并向两边递减，该模型就很好的匹配了高斯分布的形态，其对应拟合的高斯参数$\mu=180$与$\sigma=28$可以得到如下拟合图

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526081529.jpeg!small" alt="img" style="zoom: 67%;" />

可以看出数据拟合度很高，虽然仍有一定的误差，这些误差我们可以更进一步的参数调整使得模型更加拟合，也可以使用一个准确的算法来生成模型使得模型和实际值之间误差最小，最常用的算法是最大期望算法（EM）

#### 高斯混合模型

高斯混合模型则是通过多个高斯分布共同描述一个模型，假定我们不再考察全部用户的身高，而要在模型中同时考虑男性和女性的身高，那么我们上面的绘制的柱状图实际上是两个图的叠加结果（男性身高图和女性身高图）。而这两个图若是都满足高斯分布，则说明原图是由两个高斯分布所叠加而成，因此原图我们可以使用两个高斯模型来建模

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526082436.jpeg!small" alt="img" style="zoom:67%;" />

由于男性和女性的均值身高有所差异，即会产生不同的$\mu$与$\sigma$，通过多个不同的高斯模型对数据进行描述，就可以更好的保留原图所包含的信息，提高模型的匹配度，在语音信号模型中我们常常使用39维度的MFCC特征向量，因此也会产生39维高斯混合模型的叠加

换而言之，这些语音数据我们都可以通过39个高斯模型进行拟合叠加，而得到每一点对应的高斯混合模型对应的概率

### 大词汇连续语音识别问题



#### 模型训练

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526073937.png!small" alt="语音识别模型" style="zoom:67%;" />

**对于个输入语音信号：**

This is speech

**声学模型：**

其又称为「音素」，音素是最小的语音单位，通过一个或多个音素可以组成一个音节。在汉语中「这」的音素可以是「zh,e」，在英语中「this」的音素是「th,ih,s」等

因此This is speech的音素为：th-ih-s-ih-z-s-p-ih-ch

**词典：**

词典告诉了计算机，哪些音素可以组成词汇

因此th-ih-s对应this，ih-z对应is，s-p-iy-ch对应speech

**语言模型：**

但是很多音素之间的发音是十分接近的，例如s与z的发应是非常接近的，因此计算机并不能准确识别出你发的是哪一个音，只能告诉你这个音最接近哪一个，给出一个可能性分数

因此我们还需要补充一个语言模型，这个模型会告诉计算机如果我第一个词是This，那么第二个词是is的可能性有多大，第三个词是speech的可能性有多大，这三个词同时出现的可能性有多大，通过语言模型来得到最佳匹配的语句

因此输出This is speech的几率为$P=P(This)P(is\|This)P(speech\|This\ is)$

##### HMM参数

对于每一帧时刻的帧片段，我们有特征向量：$\overline{o_t}=[x_1,x_2,\cdots,x_D]^T$，对应的状态$S_{q_t}$：$q_t\in{1,2\cdots N}$

状态转移概率：$A=[a_{ij}]$，$a_{ij}=Prob[q_t=j\|q_{t-1}=i]$，即从t-1时刻是状态S1而t时刻是状态S2的概率

观测概率：$B=[b_j(\overline{o}),j=1,2,\cdots,N]$，其中$b_j(\overline{o})=\sum_{k=1}^{M}(c_{jk}b_{jk}(\overline{o}))$，而$b_{jk}(\overline{o})$是多维度下的各个高斯分布的概率值，因此$b_j(\overline{o})$是这些概率值的叠加。$c_{jk}$是所有高斯分布的权重weight，其要满足$\sum_{k=1}^{M}(c_{jk})=1$，才能输出正确的概率

起始概率：$\pi=[\pi_1,\pi_2\,cdots,\pi_N]$，$\pi_i=Prob[q1=i]$，即选择该点作为起始点的概率（语音输入的起始点并不固定，可以有很多个，因此不同的起始点会影响后面的判决）

因此HMM输入输出：$HMM(A,B,\pi)=\lambda$

### 语音处理

#### 特征提取（端点处理算法）

+ 高频部分预增强：高频段的振幅往往较小，提高高频段便于学习

  $H(z)=1-az^{-1}$，$0\ll a<1$

+ 端点检测：有声段/无声段检测，去除多余的信号，减少机器学习的负担

  + 短时帧能量
  + 短时帧过零点数

+ 加Hamming窗：柔滑过渡段语音信号

  $w[m]=\left\\{\begin{matrix}0.54-0.46cos[\frac{2\pi m}{L}],0\leq m\leq L-1\\\\ 0,else \end{matrix}\right.$
  
+ MFCC特征提取：将「时间域的信号特征」转化成「频域的信号特征」

  + 加窗后的短时帧信号
  + 傅里叶变换
  + 经过Mel滤波器
  + 做绝对值平方的对数
  + 做逆离散傅里叶变换IDFT
  + 得到MFCC

  得到的MFCC只有13维信息，我们要继续求解一次微分和两次微分得到39维信息

#### 语言模型

让计算机读取非常多的文章，让它学到这些词句两两相连、三三相连的几率帮助得到整个句子的几率

例如：计算机根据输入语音对每一个词判决如下：$W=(\begin{bmatrix}w_{11}\\ w_{12}\\ \cdots\\ w_{1n}\end{bmatrix},\begin{bmatrix}w_{21}\\ w_{22}\\ \cdots\\ w_{2n}\end{bmatrix},\cdots,\begin{bmatrix}w_{k1}\\ w_{k2}\\ \cdots\\ w_{kn}\end{bmatrix})$，$w_{ij}$表示第i个词可能为第j词（假设第一个词发应为wo，计算机可以判决为「我」、「沃」……）

那么计算机就要去判决这些词两两组合，三三组合成为一整个句子的概率，若是第二个词发音为xihuan，同理计算机可以判决为「喜欢」、「西环」，但是根据前后文组合，「我-喜欢」成为一组的可能性会远高于其他组别，因此判决这句话为「我喜欢……」的概率就会更高

计算机会去判决所有可能的组合，选择出可能性最高的一组做为语句的输出，而这样一个前后文学习的积累，就是通过语言模型来建立的





